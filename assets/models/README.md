# ü§ñ Modelo YOLOv11 - Gu√≠a de Configuraci√≥n

Este directorio debe contener el modelo YOLOv11 convertido a TensorFlow Lite para la detecci√≥n de poses.

## üì¶ Archivo Requerido

```
assets/models/yolov11_pose.tflite
```

**Tama√±o esperado**: 5-50 MB (dependiendo de la variante del modelo)

## üîß Conversi√≥n del Modelo

### Requisitos

```bash
pip install ultralytics torch onnx tensorflow
```

### Opci√≥n 1: Modelo Preentrenado (Recomendado)

```python
from ultralytics import YOLO

# Cargar modelo preentrenado de Ultralytics
model = YOLO('yolov11n-pose.pt')  # 'n' = nano (m√°s r√°pido)
# Alternativas: yolov11s-pose.pt, yolov11m-pose.pt, yolov11l-pose.pt

# Exportar a TFLite
model.export(
    format='tflite',
    imgsz=640,  # Tama√±o de entrada (640x640)
    int8=False,  # Usar int8=True para cuantizaci√≥n (modelo m√°s peque√±o)
    nms=True     # Incluir Non-Maximum Suppression
)
```

El archivo resultante se llamar√° `yolov11n-pose_saved_model/yolov11n-pose_float32.tflite`

### Opci√≥n 2: Desde ONNX

```python
import onnx
from onnx_tf.backend import prepare
import tensorflow as tf

# 1. Exportar PyTorch ‚Üí ONNX
model = YOLO('yolov11n-pose.pt')
model.export(format='onnx', imgsz=640)

# 2. Convertir ONNX ‚Üí TensorFlow
onnx_model = onnx.load('yolov11n-pose.onnx')
tf_rep = prepare(onnx_model)
tf_rep.export_graph('yolov11_pose_tf')

# 3. Convertir TensorFlow ‚Üí TFLite
converter = tf.lite.TFLiteConverter.from_saved_model('yolov11_pose_tf')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# Guardar
with open('yolov11_pose.tflite', 'wb') as f:
    f.write(tflite_model)
```

### Opci√≥n 3: Con Cuantizaci√≥n (Modelo m√°s peque√±o)

```python
from ultralytics import YOLO

model = YOLO('yolov11n-pose.pt')

# Exportar con cuantizaci√≥n INT8
model.export(
    format='tflite',
    imgsz=640,
    int8=True,  # Reduce tama√±o ~4x pero puede perder precisi√≥n
    data='coco-pose.yaml'  # Dataset para calibraci√≥n
)
```

## üìã Especificaciones del Modelo

### Entrada Esperada

- **Formato**: RGB
- **Tama√±o**: 640x640 p√≠xeles
- **Tipo**: float32 [0.0, 1.0] (normalizado)
- **Shape**: `[1, 640, 640, 3]` (batch, height, width, channels)

### Salida Esperada

- **Formato**: 17 keypoints COCO
- **Tipo**: float32
- **Shape**: `[1, num_detections, 51]` donde:
  - `51 = 4 (bbox) + 1 (confidence) + 1 (class) + 45 (17 keypoints √ó 3)`
  - Cada keypoint: `[x, y, visibility]`

### Keypoints COCO (17 puntos)

```
0:  nose            (nariz)
1:  left_eye        (ojo izquierdo)
2:  right_eye       (ojo derecho)
3:  left_ear        (oreja izquierda)
4:  right_ear       (oreja derecha)
5:  left_shoulder   (hombro izquierdo)   ‚Üê Usado para flexiones
6:  right_shoulder  (hombro derecho)     ‚Üê Usado para flexiones
7:  left_elbow      (codo izquierdo)     ‚Üê CR√çTICO para flexiones
8:  right_elbow     (codo derecho)       ‚Üê CR√çTICO para flexiones
9:  left_wrist      (mu√±eca izquierda)   ‚Üê Usado para flexiones
10: right_wrist     (mu√±eca derecha)     ‚Üê Usado para flexiones
11: left_hip        (cadera izquierda)   ‚Üê Usado para alineaci√≥n
12: right_hip       (cadera derecha)     ‚Üê Usado para alineaci√≥n
13: left_knee       (rodilla izquierda)
14: right_knee      (rodilla derecha)
15: left_ankle      (tobillo izquierdo)
16: right_ankle     (tobillo derecho)
```

## üéØ Variantes del Modelo

| Variante | Tama√±o | Velocidad | Precisi√≥n | Recomendaci√≥n  |
| -------- | ------ | --------- | --------- | -------------- |
| YOLOv11n | ~5 MB  | ~50 FPS   | 85%       | ‚úÖ **M√≥viles** |
| YOLOv11s | ~12 MB | ~40 FPS   | 88%       | Balanceado     |
| YOLOv11m | ~25 MB | ~30 FPS   | 90%       | Alta precisi√≥n |
| YOLOv11l | ~50 MB | ~20 FPS   | 92%       | Computadoras   |

**Para esta app, se recomienda YOLOv11n** (nano) por el balance entre velocidad y precisi√≥n en dispositivos m√≥viles.

## ‚úÖ Verificaci√≥n del Modelo

### Comprobar que el modelo funciona

```python
import tensorflow as tf
import numpy as np

# Cargar modelo
interpreter = tf.lite.Interpreter(model_path="yolov11_pose.tflite")
interpreter.allocate_tensors()

# Obtener detalles de entrada/salida
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print("=== INPUT ===")
print(f"Shape: {input_details[0]['shape']}")
print(f"Type: {input_details[0]['dtype']}")

print("\n=== OUTPUT ===")
print(f"Shape: {output_details[0]['shape']}")
print(f"Type: {output_details[0]['dtype']}")

# Test con imagen dummy
dummy_input = np.random.rand(1, 640, 640, 3).astype(np.float32)
interpreter.set_tensor(input_details[0]['index'], dummy_input)
interpreter.invoke()
output = interpreter.get_tensor(output_details[0]['index'])

print(f"\n‚úÖ Modelo funciona correctamente!")
print(f"Output shape: {output.shape}")
```

### Comprobar tama√±o

```bash
# Windows PowerShell
Get-Item yolov11_pose.tflite | Select-Object Name, @{Name="Size(MB)";Expression={[math]::Round($_.Length/1MB, 2)}}

# Linux/Mac
ls -lh yolov11_pose.tflite
```

## üìö Recursos Adicionales

- [Ultralytics YOLOv11 Docs](https://docs.ultralytics.com/models/yolov11/)
- [COCO Pose Dataset](https://cocodataset.org/#keypoints-2020)
- [TFLite Converter Guide](https://www.tensorflow.org/lite/convert)
- [YOLO Export Formats](https://docs.ultralytics.com/modes/export/)

## ‚ö†Ô∏è Troubleshooting

### Error: "Failed to load model"

1. Verifica que el archivo se llame **exactamente** `yolov11_pose.tflite`
2. Ejecuta `flutter clean && flutter pub get`
3. Reconstruye la app

### Error: "Invalid input shape"

- El modelo debe aceptar entrada `[1, 640, 640, 3]`
- Revisa la exportaci√≥n con `imgsz=640`

### Modelo muy lento

- Usa YOLOv11n en lugar de modelos m√°s grandes
- Activa cuantizaci√≥n INT8
- Reduce la resoluci√≥n de la c√°mara

### Baja precisi√≥n

- No uses cuantizaci√≥n INT8
- Usa YOLOv11s o YOLOv11m
- Ajusta `confidenceThreshold` en `yolo_detector.dart`

## üîÑ Script de Descarga Autom√°tica

```bash
# download_model.sh
#!/bin/bash

pip install ultralytics

python3 << EOF
from ultralytics import YOLO

print("üì• Descargando YOLOv11n-pose...")
model = YOLO('yolov11n-pose.pt')

print("üîÑ Convirtiendo a TFLite...")
model.export(format='tflite', imgsz=640)

print("‚úÖ Modelo listo!")
EOF

mv yolov11n-pose_saved_model/yolov11n-pose_float32.tflite ./yolov11_pose.tflite
echo "‚úÖ Modelo guardado como yolov11_pose.tflite"
```

---

**√öltima actualizaci√≥n**: 2024  
**Modelo requerido**: YOLOv11-pose (COCO keypoints)  
**Formato**: TensorFlow Lite (.tflite)
